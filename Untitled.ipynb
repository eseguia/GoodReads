{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebeedfc",
   "metadata": {},
   "source": [
    "### GoodReads Dataset\n",
    "\n",
    "1. [Loading required libraries, with installation](#1)\n",
    "\n",
    "2. [Getting basic ideas about the data](#2)\n",
    "\n",
    "3. [Exploratory Data Analysis](#3)\n",
    "    1. [Which are the books with most occurances in the list?](#4)\n",
    "    2. [What is the distribution of books across languages?](#5)\n",
    "    3. [Which are the top 10 most rated books?](#6)\n",
    "    4. [Which are the authors with most books?](#7)\n",
    "    5. [Performance of an author over time:](#8)\n",
    "        \n",
    "        1. [Stephen King](#9)\n",
    "        \n",
    "        2. [Agatha Christie](#10)\n",
    "        \n",
    "        3. [Dan Brown](#11)\n",
    "        \n",
    "        4. [J.K. Rowling](#12)\n",
    "        \n",
    "    6. [Which are the top 10 highly rated authors?](#13)\n",
    "    7. [What is the rating distribution for the books?](#14)\n",
    "    8. [Is there relationship between ratings and review counts?](#15)\n",
    "    9. [Is there a relationship between number of pages and ratings?](#16)\n",
    "    10. [Is there a relationship between ratings and ratings count?](#17)\n",
    "    11. [Which are the books with the highest reviews?](#18)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "804ac731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting isbnlib\n",
      "  Downloading isbnlib-3.10.10-py2.py3-none-any.whl (66 kB)\n",
      "Installing collected packages: isbnlib\n",
      "Successfully installed isbnlib-3.10.10\n",
      "Collecting newspaper3k\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (4.10.0)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (3.3.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (2.26.0)\n",
      "Collecting feedfinder2>=0.0.4\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "Collecting jieba3k>=0.35.1\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (2.8.2)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (4.6.3)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (3.6.5)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (8.4.0)\n",
      "Collecting feedparser>=5.2.1\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "Collecting tinysegmenter==0.3\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from newspaper3k) (6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.2.1)\n",
      "Requirement already satisfied: six in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.62.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (1.26.7)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.3.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.4)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13552 sha256=ebbcd7a1e2296bf6db56c6f9cc0d005dbe933ee81195b8ee19d2f22122cdb12d\n",
      "  Stored in directory: c:\\users\\emilio\\appdata\\local\\pip\\cache\\wheels\\94\\ad\\df\\a2a01300cea47d5695f242f7e925a805970106fd9e4b151468\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3356 sha256=de86cf5a88b8ba065dea84f1ac40defbf3e17c20aa221563870c736a2886a0df\n",
      "  Stored in directory: c:\\users\\emilio\\appdata\\local\\pip\\cache\\wheels\\43\\4a\\c2\\61a371b2524ac90805391c660d8dc4505705297f25e2b85a5d\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398405 sha256=b35e1094450db505e3438c8b5b6796b70ad777675fcef15f40bcf5a7df6c8fe2\n",
      "  Stored in directory: c:\\users\\emilio\\appdata\\local\\pip\\cache\\wheels\\c2\\22\\59\\8214a8d6357e9f540ce1f37f9a4362b6156b4ca81b37f1945f\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=146226be5cad3dc9c7bf3fc07c2c1292f0d1401bd188c423a62c868de3dec527\n",
      "  Stored in directory: c:\\users\\emilio\\appdata\\local\\pip\\cache\\wheels\\65\\7a\\a7\\78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: sgmllib3k, tinysegmenter, jieba3k, feedparser, feedfinder2, newspaper3k\n",
      "Successfully installed feedfinder2-0.0.4 feedparser-6.0.10 jieba3k-0.35.1 newspaper3k-0.2.8 sgmllib3k-1.0.0 tinysegmenter-0.3\n",
      "Collecting goodreads_api_client\n",
      "  Downloading goodreads_api_client-0.1.0.dev4-py2.py3-none-any.whl (29 kB)\n",
      "Collecting requests==2.18.3\n",
      "  Downloading requests-2.18.3-py2.py3-none-any.whl (88 kB)\n",
      "Collecting xmltodict==0.11.0\n",
      "  Downloading xmltodict-0.11.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Collecting rauth==0.7.3\n",
      "  Downloading rauth-0.7.3.tar.gz (16 kB)\n",
      "Collecting idna<2.6,>=2.5\n",
      "  Downloading idna-2.5-py2.py3-none-any.whl (55 kB)\n",
      "Collecting urllib3<1.23,>=1.21.1\n",
      "  Downloading urllib3-1.22-py2.py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emilio\\anaconda3\\lib\\site-packages (from requests==2.18.3->goodreads_api_client) (2022.6.15)\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Building wheels for collected packages: rauth\n",
      "  Building wheel for rauth (setup.py): started\n",
      "  Building wheel for rauth (setup.py): finished with status 'done'\n",
      "  Created wheel for rauth: filename=rauth-0.7.3-py3-none-any.whl size=16081 sha256=c7823a812e148f37a4ec0fcf5bec4e64d8dd49dc9c495d2377da6e3c0705057d\n",
      "  Stored in directory: c:\\users\\emilio\\appdata\\local\\pip\\cache\\wheels\\e8\\bf\\f8\\fe5ecf3f58dd944bdf853ce2d995b3dddef2a2fea48d1f84bc\n",
      "Successfully built rauth\n",
      "Installing collected packages: urllib3, idna, chardet, requests, xmltodict, rauth, goodreads-api-client\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Uninstalling urllib3-1.26.7:\n",
      "      Successfully uninstalled urllib3-1.26.7\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.2\n",
      "    Uninstalling idna-3.2:\n",
      "      Successfully uninstalled idna-3.2\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.26.0\n",
      "    Uninstalling requests-2.26.0:\n",
      "      Successfully uninstalled requests-2.26.0\n",
      "  Attempting uninstall: xmltodict\n",
      "    Found existing installation: xmltodict 0.12.0\n",
      "    Uninstalling xmltodict-0.12.0:\n",
      "      Successfully uninstalled xmltodict-0.12.0\n",
      "Successfully installed chardet-3.0.4 goodreads-api-client-0.1.0.dev4 idna-2.5 rauth-0.7.3 requests-2.18.3 urllib3-1.22 xmltodict-0.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n",
      "cookiecutter 1.7.2 requires requests>=2.23.0, but you have requests 2.18.3 which is incompatible.\n",
      "botocore 1.27.43 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.22 which is incompatible.\n",
      "anyio 2.2.0 requires idna>=2.8, but you have idna 2.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install isbnlib\n",
    "!pip install newspaper3k\n",
    "!pip install goodreads_api_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5db756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import isbnlib\n",
    "from newspaper import Article\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "from pylab import plot, show\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as mcolors\n",
    "import goodreads_api_client as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81dd99c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 12 fields in line 3350, saw 13\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18608/2087622339.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'books.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 12 fields in line 3350, saw 13\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6373d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df['bookID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632753f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset contains {} rows and {} columns\".format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb67cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(to_replace='J.K. Rowling-Mary GrandPré', value = 'J.K. Rowling', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf0f37",
   "metadata": {},
   "source": [
    "#### Columns Description: \n",
    "\n",
    "- **bookID** Contains the unique ID for each book/series\n",
    "- **title** contains the titles of the books\n",
    "- **authors** contains the author of the particular book\n",
    "- **average_rating** the average rating of the books, as decided by the users\n",
    "- **ISBN** ISBN(10) number, tells the information about a book - such as edition and publisher\n",
    "- **ISBN 13** The new format for ISBN, implemented in 2007. 13 digits\n",
    "- **language_code** Tells the language for the books\n",
    "- **Num_pages** Contains the number of pages for the book\n",
    "- **Ratings_count** Contains the number of ratings given for the book\n",
    "- **text_reviews_count** Has the count of reviews left by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e23d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
